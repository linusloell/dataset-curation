{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linusloell/dataset-curation/blob/main/dataset_curation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kxl_UoHXhpe8",
      "metadata": {
        "id": "kxl_UoHXhpe8"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KhuRfshRht0i",
      "metadata": {
        "id": "KhuRfshRht0i"
      },
      "source": [
        "## 0.1 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "RwDC1RhqPNNd",
      "metadata": {
        "id": "RwDC1RhqPNNd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!uv pip install fiftyone==1.7.0 torch==2.6.0 torchvision==0.21 numpy==2.0.2 open-clip-torch==3.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "QGh3eSFPJJ4O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGh3eSFPJJ4O",
        "outputId": "4acc0ecb-d249-4129-c2a1-a75a83cd0610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading voxel51/fiftyone-plugins...\n",
            "  329.4Mb [5.9s elapsed, ? remaining, 66.2Mb/s]    \n",
            "Copying plugin '@voxel51/evaluation' to '/home/linus/fiftyone/__plugins__/@voxel51/evaluation'\n",
            "Downloading jacobmarks/clustering-plugin...\n",
            "  162.8Kb [19.1ms elapsed, ? remaining, 8.3Mb/s] \n",
            "Copying plugin '@jacobmarks/clustering' to '/home/linus/fiftyone/__plugins__/@jacobmarks/clustering'\n"
          ]
        }
      ],
      "source": [
        "# Plug-in to evaluate the performance of our classification models\n",
        "!fiftyone plugins download \\\n",
        "    https://github.com/voxel51/fiftyone-plugins \\\n",
        "    --plugin-names @voxel51/evaluation\n",
        "!fiftyone plugins download https://github.com/jacobmarks/clustering-plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "X1gxIeI5Ir39",
      "metadata": {
        "id": "X1gxIeI5Ir39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/linus/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables for reproducibility BEFORE importing torch\n",
        "os.environ['PYTHONHASHSEED'] = '51'\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fun\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "from fiftyone import ViewField as F\n",
        "import fiftyone.utils.random as four\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, Any\n",
        "from huggingface_hub import notebook_login\n",
        "import fiftyone.utils.huggingface as fouh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WkclDoRzh3sj",
      "metadata": {
        "id": "WkclDoRzh3sj"
      },
      "source": [
        "## 0.1 Load Data and set random seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25907b19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "25907b19",
        "outputId": "7d1e86ed-6f54-4f90-b5c6-3913d799764c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "i-VJ7ajbq16D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-VJ7ajbq16D",
        "outputId": "bacc4469-877f-4d60-aa96-8f038450f68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All random seeds set to 51 for reproducibility\n"
          ]
        }
      ],
      "source": [
        "def set_seeds(seed=51):\n",
        "    \"\"\"\n",
        "    Set seeds for complete reproducibility across all libraries and operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int): Random seed value\n",
        "    \"\"\"\n",
        "    # Set environment variables before other imports\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "    # Python random module\n",
        "    # random.seed(seed)\n",
        "\n",
        "    # NumPy\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # PyTorch CPU\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # PyTorch GPU (all devices)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
        "\n",
        "        # CUDA deterministic operations\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # OpenCV\n",
        "    #cv2.setRNGSeed(seed)\n",
        "\n",
        "    # Albumentations (for data augmentation)\n",
        "    #try:\n",
        "        #A.seed_everything(seed)\n",
        "    #except AttributeError:\n",
        "        # Older versions of albumentations\n",
        "    #    pass\n",
        "\n",
        "    # PyTorch deterministic algorithms (may impact performance)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except RuntimeError:\n",
        "        # Some operations don't have deterministic implementations\n",
        "        print(\"Warning: Some operations may not be deterministic\")\n",
        "\n",
        "    print(f\"All random seeds set to {seed} for reproducibility\")\n",
        "\n",
        "\n",
        "\n",
        "# Usage: Call this function at the beginning and before each training phase\n",
        "set_seeds(51)\n",
        "\n",
        "def create_deterministic_training_dataloader(dataset, batch_size, shuffle=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Create a DataLoader with deterministic behavior.\n",
        "\n",
        "    Args:\n",
        "        dataset: PyTorch Dataset instance\n",
        "        batch_size: Batch size\n",
        "        shuffle: Whether to shuffle data\n",
        "        **kwargs: Additional DataLoader arguments\n",
        "\n",
        "    Returns:\n",
        "        Training DataLoader with reproducible behavior\n",
        "    \"\"\"\n",
        "    # Use a generator with fixed seed for reproducible shuffling\n",
        "    generator = torch.Generator()\n",
        "    generator.manual_seed(51)\n",
        "\n",
        "    return torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        generator=generator if shuffle else None,\n",
        "        **kwargs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "NezpK2qr18h3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NezpK2qr18h3",
        "outputId": "b8fc9776-821f-4278-a067-2e026f0d7e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'train' already downloaded\n",
            "Loading existing dataset 'mnist-train-val'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
            "Split 'test' already downloaded\n",
            "Loading existing dataset 'mnist-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "train_val_dataset = foz.load_zoo_dataset(\"mnist\",\n",
        "                                         split='train',\n",
        "                                         dataset_name=\"mnist-train-val\",\n",
        "                                         persistent=True)\n",
        "test_dataset = foz.load_zoo_dataset(\"mnist\",\n",
        "                                    split='test',\n",
        "                                    dataset_name=\"mnist-test\",\n",
        "                                    persistent=True)\n",
        "train_val_dataset.compute_metadata()\n",
        "test_dataset.compute_metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7M9_3Gri26Wo",
      "metadata": {
        "id": "7M9_3Gri26Wo"
      },
      "outputs": [],
      "source": [
        "# The images come with the 'train' tag and this must be deleted\n",
        "# at the sample level.\n",
        "train_val_dataset.untag_samples([\"train\", \"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ZSxkOev3T_4O",
      "metadata": {
        "id": "ZSxkOev3T_4O"
      },
      "outputs": [],
      "source": [
        "# delete existing datasets\n",
        "if (fo.dataset_exists(\"mnist-training-set\")):\n",
        "    fo.delete_dataset(\"mnist-training-set\")\n",
        "\n",
        "if fo.dataset_exists(\"mnist-validation-set\"):\n",
        "    fo.delete_dataset(\"mnist-validation-set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "YfPp1Huh2258",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfPp1Huh2258",
        "outputId": "94dcdd11-2f63-470e-ef8f-bd52654a310a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All random seeds set to 51 for reproducibility\n",
            "Tag counts after split:\n",
            "{'validation': 9000, 'mistaken': 47, 'train': 51000, 'hard': 35}\n"
          ]
        }
      ],
      "source": [
        "set_seeds(51)\n",
        "# Create random 85%/15% split using tags\n",
        "four.random_split(train_val_dataset,\n",
        "                  {\"train\": 0.85, \"validation\": 0.15},\n",
        "                  # The seed makes the split reproducible\n",
        "                  seed=51)\n",
        "\n",
        "# Verify the split by counting tags\n",
        "tag_counts = train_val_dataset.count_sample_tags()\n",
        "print(\"Tag counts after split:\")\n",
        "print(tag_counts)\n",
        "\n",
        "# Separate validation and train FO datasets\n",
        "train_dataset = train_val_dataset.match_tags(\"train\").clone()\n",
        "val_dataset = train_val_dataset.match_tags(\"validation\").clone()\n",
        "\n",
        "# Set names for FO datasets using the 'name' property\n",
        "train_dataset.name = \"mnist-training-set\"\n",
        "val_dataset.name = \"mnist-validation-set\"\n",
        "\n",
        "# Define persistency\n",
        "train_dataset.persistent = True\n",
        "val_dataset.persistent = True\n",
        "\n",
        "# Verify no overlap between train and validation\n",
        "train_ids = set(train_dataset.values(\"id\"))\n",
        "val_ids = set(val_dataset.values(\"id\"))\n",
        "overlap = train_ids.intersection(val_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3zcr6BiFJaNZ",
      "metadata": {
        "id": "3zcr6BiFJaNZ"
      },
      "outputs": [],
      "source": [
        "dataset_classes = sorted(test_dataset.distinct(\"ground_truth.label\"))\n",
        "label_map = {string_label: index for index, string_label in enumerate(dataset_classes)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "hPlCd7XLnsKJ",
      "metadata": {
        "collapsed": true,
        "id": "hPlCd7XLnsKJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "http://localhost:5151/\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(train_dataset, auto=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wJGsyXc_HAZ5",
      "metadata": {
        "id": "wJGsyXc_HAZ5"
      },
      "source": [
        "# 1. Training LeNet5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zIfYwxrObFYS",
      "metadata": {
        "id": "zIfYwxrObFYS"
      },
      "source": [
        "## 2.1 Defining the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ibzNb_uEaxM5",
      "metadata": {
        "id": "ibzNb_uEaxM5"
      },
      "source": [
        "### Model Architecure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "Ut83kkWwG_Xq",
      "metadata": {
        "id": "Ut83kkWwG_Xq"
      },
      "outputs": [],
      "source": [
        "class ModernLeNet5(nn.Module):\n",
        "    \"\"\"\n",
        "    Modernized version of LeNet-5 with ReLU activations and max pooling.\n",
        "    Often performs better on MNIST than the original version.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ModernLeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=4)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.relu(self.conv3(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8C29CIg_a0Si",
      "metadata": {
        "id": "8C29CIg_a0Si"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "xFVPZ31NHfEV",
      "metadata": {
        "id": "xFVPZ31NHfEV"
      },
      "outputs": [],
      "source": [
        "class CustomTorchImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, fiftyone_dataset, image_transforms=None, label_map=None):\n",
        "        self.image_paths = fiftyone_dataset.values(\"filepath\")\n",
        "        self.str_labels = fiftyone_dataset.values(\"ground_truth.label\")\n",
        "        self.image_transforms = image_transforms\n",
        "        self.label_map = label_map or {str(i): i for i in range(10)}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('L')\n",
        "        if self.image_transforms:\n",
        "            image = self.image_transforms(image)\n",
        "\n",
        "        label_str = self.str_labels[idx]\n",
        "        label_idx = self.label_map[label_str]\n",
        "\n",
        "        return image, torch.tensor(label_idx, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dmOYNo4mH876",
      "metadata": {
        "id": "dmOYNo4mH876"
      },
      "outputs": [],
      "source": [
        "dataset_classes = sorted(test_dataset.distinct(\"ground_truth.label\"))\n",
        "label_map = {string_label: index for index, string_label in enumerate(dataset_classes)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "BwV9Hgh-E-PX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "BwV9Hgh-E-PX",
        "outputId": "fc222a3b-7a39-4960-d40e-f3f0016d56e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing image intensity statistics from FiftyOne view...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51000/51000 [00:10<00:00, 4815.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed from 51000 images\n",
            "Total pixels: 39,984,000\n",
            "Computing image intensity statistics from FiftyOne view...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9000/9000 [00:02<00:00, 4321.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed from 9000 images\n",
            "Total pixels: 7,056,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'VAL: Mean: 0.1319, Std: 0.3075'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_stats_fiftyone(fiftyone_view):\n",
        "    \"\"\"\n",
        "    Compute stats directly from FiftyOne using aggregations.\n",
        "    Requires images to be loaded as arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Computing image intensity statistics from FiftyOne view...\")\n",
        "\n",
        "    # Get all image filepaths\n",
        "    filepaths = fiftyone_view.values(\"filepath\")\n",
        "\n",
        "    # Load all pixel values\n",
        "    all_pixels = []\n",
        "\n",
        "    for filepath in tqdm(filepaths):\n",
        "\n",
        "        try:\n",
        "            # Load image as grayscale array\n",
        "            image = Image.open(filepath).convert('L')\n",
        "            # Scale values to the range [0, 1]\n",
        "            pixels = np.array(image, dtype=np.float32) / 255.0\n",
        "            all_pixels.append(pixels.flatten())\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {filepath}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Concatenate all pixel values\n",
        "    all_pixels = np.concatenate(all_pixels)\n",
        "\n",
        "    # Compute statistics\n",
        "    mean = np.mean(all_pixels)\n",
        "    std = np.std(all_pixels)\n",
        "\n",
        "    print(f\"Computed from {len(filepaths)} images\")\n",
        "    print(f\"Total pixels: {len(all_pixels):,}\")\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "mean_intensity, std_intensity = compute_stats_fiftyone(train_dataset)\n",
        "f\"TRAIN: Mean: {mean_intensity:.4f}, Std: {std_intensity:.4f}\"\n",
        "mean_intensity, std_intensity = compute_stats_fiftyone(val_dataset)\n",
        "f\"VAL: Mean: {mean_intensity:.4f}, Std: {std_intensity:.4f}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6Xr_lCpPDvBV",
      "metadata": {
        "id": "6Xr_lCpPDvBV"
      },
      "outputs": [],
      "source": [
        "image_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize((mean_intensity,), (std_intensity,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bZpMBS8MBbdN",
      "metadata": {
        "id": "bZpMBS8MBbdN"
      },
      "outputs": [],
      "source": [
        "torch_train_set = CustomTorchImageDataset(train_dataset,\n",
        "                                          label_map=label_map,\n",
        "                                          image_transforms=image_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "98QofkjSBqiE",
      "metadata": {
        "id": "98QofkjSBqiE"
      },
      "outputs": [],
      "source": [
        "torch_val_set = CustomTorchImageDataset(val_dataset,\n",
        "                                     label_map=label_map,\n",
        "                                     image_transforms=image_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AY5sqIYwUrIs",
      "metadata": {
        "id": "AY5sqIYwUrIs"
      },
      "source": [
        "### data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bb36104f",
      "metadata": {
        "id": "bb36104f"
      },
      "outputs": [],
      "source": [
        "# Define batch size (you can adjust this based on your GPU memory)\n",
        "batch_size = 64\n",
        "num_workers = os.cpu_count()  # Number of CPU cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8uiiduZxDxIZ",
      "metadata": {
        "id": "8uiiduZxDxIZ"
      },
      "outputs": [],
      "source": [
        "train_loader = create_deterministic_training_dataloader(\n",
        "    torch_train_set,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "wD9r7mMUDt7B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD9r7mMUDt7B",
        "outputId": "48eb32ba-8add-4f1c-e4e2-4264f9c7e090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and validation DataLoaders created successfully.\n",
            "Train DataLoader has 797 batches.\n",
            "Validation DataLoader has 141 batches.\n"
          ]
        }
      ],
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "    torch_val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Train and validation DataLoaders created successfully.\")\n",
        "print(f\"Train DataLoader has {len(train_loader)} batches.\")\n",
        "print(f\"Validation DataLoader has {len(val_loader)} batches.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eVEsqzKpZbui",
      "metadata": {
        "id": "eVEsqzKpZbui"
      },
      "source": [
        "### Loss-Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fotF_KQ1Za0a",
      "metadata": {
        "id": "fotF_KQ1Za0a"
      },
      "outputs": [],
      "source": [
        "ce_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WIDwxahHaXsF",
      "metadata": {
        "id": "WIDwxahHaXsF"
      },
      "source": [
        "### define model and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3oxrG6-UaShy",
      "metadata": {
        "id": "3oxrG6-UaShy"
      },
      "outputs": [],
      "source": [
        "model = ModernLeNet5().to(device)\n",
        "\n",
        "# Define the optimizer (variant of stochastic gradient descent)\n",
        "optimizer = Adam(model.parameters(),\n",
        "                 lr=0.003, betas=(0.9, 0.999),\n",
        "                 eps=1e-08, weight_decay=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W1E8hW0SaDtr",
      "metadata": {
        "id": "W1E8hW0SaDtr"
      },
      "source": [
        "### train and validate methodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "zvXszqWQ4dAn",
      "metadata": {
        "id": "zvXszqWQ4dAn"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader):\n",
        "  batch_losses = []\n",
        "  model.train()\n",
        "  for images, labels in tqdm(train_loader, desc=\"Training: \"):\n",
        "      #import pdb; pdb.set_trace()\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Forward pass\n",
        "      logits = model(images)\n",
        "      loss_value = ce_loss(logits, labels)\n",
        "      # Clear gradients from previous iteration (PyTorch accumulates by default)\n",
        "      optimizer.zero_grad()\n",
        "      # Computes the gradients with backpropagation\n",
        "      loss_value.backward()\n",
        "      # Updates the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      batch_losses.append(loss_value.item())\n",
        "\n",
        "  train_loss = np.mean(batch_losses)\n",
        "  return train_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "mAf9bjcX51pf",
      "metadata": {
        "id": "mAf9bjcX51pf"
      },
      "outputs": [],
      "source": [
        "def val_epoch(model, val_loader):\n",
        "  batch_losses = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for images, labels in tqdm(val_loader, desc=\"Validation: \"):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Forward pass\n",
        "      logits = model(images)\n",
        "      loss_value = ce_loss(logits, labels)\n",
        "      batch_losses.append(loss_value.item())\n",
        "  val_loss = np.mean(batch_losses)\n",
        "  return val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N1q5tQxsa_8I",
      "metadata": {
        "id": "N1q5tQxsa_8I"
      },
      "source": [
        "## 2.2 Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "0_FcD3v_bPML",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_FcD3v_bPML",
        "outputId": "61c57e34-d17f-441f-b894-483d3929330d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All random seeds set to 51 for reproducibility\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/797 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:22<00:00, 35.76it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 92.04it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train Loss: 0.2188 - Val Loss: 0.0825\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 83.86it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 108.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Train Loss: 0.0801 - Val Loss: 0.0653\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 87.43it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 104.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Train Loss: 0.0633 - Val Loss: 0.0552\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 86.42it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 104.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Train Loss: 0.0503 - Val Loss: 0.0501\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 86.48it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 107.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Train Loss: 0.0455 - Val Loss: 0.0525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 88.37it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 108.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Train Loss: 0.0442 - Val Loss: 0.0648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 88.22it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 98.17it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Train Loss: 0.0386 - Val Loss: 0.0596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:09<00:00, 87.03it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 101.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Train Loss: 0.0397 - Val Loss: 0.0530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:08<00:00, 89.75it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 99.10it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Train Loss: 0.0311 - Val Loss: 0.0652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 797/797 [00:08<00:00, 89.83it/s] \n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 103.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Train Loss: 0.0373 - Val Loss: 0.0588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Ensure reproducibility for the training process\n",
        "set_seeds(51) # You can change this number to get different results\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_model = None\n",
        "\n",
        "# Define the path to save the model within your hard-drive\n",
        "path = Path(os.getcwd()) # Feel free to change the path\n",
        "\n",
        "model_save_path = path / 'best_lenet.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = val_epoch(model, val_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "        # Save the best model\n",
        "        torch.save(best_model.state_dict(), model_save_path)\n",
        "        print('Found and saved better weights for the model')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vashjqlpduVT",
      "metadata": {
        "id": "vashjqlpduVT"
      },
      "source": [
        "### visualize training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ZwEOvk1FdPAG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ZwEOvk1FdPAG",
        "outputId": "36c9566d-658b-48ce-c21c-85d3eac48186"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Find the epoch with the best validation loss\n",
        "best_epoch = np.argmin(val_losses) + 1 # Add 1 because epochs are 1-indexed\n",
        "\n",
        "# Add a vertical red line at the epoch with the best validation loss\n",
        "plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Val Loss Epoch {best_epoch}')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ENNWUrugdpzb",
      "metadata": {
        "id": "ENNWUrugdpzb"
      },
      "source": [
        "### Load best version of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6mKrv5uAdnNl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mKrv5uAdnNl",
        "outputId": "5a11e369-9999-4f48-bdbe-42c579d465eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully from /home/linus/HPI/cv-seminar/best_lenet.pth\n",
            "Model is on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Define the path where the best model was saved\n",
        "path = Path(os.getcwd())\n",
        "model_save_path = path / 'best_lenet.pth'\n",
        "\n",
        "# Instantiate a new model with the same architecture\n",
        "# Make sure you use the same model class that was trained\n",
        "loaded_model = ModernLeNet5()\n",
        "\n",
        "# Load the saved state dictionary into the new model instance\n",
        "# Make sure the model is on the correct device (CPU or GPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "\n",
        "# Move the model to the device\n",
        "loaded_model = loaded_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully from {model_save_path}\")\n",
        "print(f\"Model is on device: {next(loaded_model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "GeDw14CyaaMO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "GeDw14CyaaMO",
        "outputId": "814503b9-1204-4242-d788-92048843a2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying LeNet model to the train_dataset (using non-shuffled loader)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing train batches for inference: 100%|██████████| 797/797 [00:07<00:00, 108.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference on train_dataset complete.\n",
            "Shape of collected train logits: (51000, 10)\n",
            "Number of collected train predictions: 51000\n",
            "Storing predictions and logits as FiftyOne Classifications for train_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing train classifications: 100%|██████████| 51000/51000 [01:47<00:00, 476.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions and logits stored successfully as FiftyOne Classifications for train_dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# This uses the torch_train_set which is derived from train_dataset\n",
        "train_inference_loader = torch.utils.data.DataLoader(\n",
        "    torch_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # CRITICAL: Must be False for ordered predictions\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Set the loaded model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# Lists to store predictions and logits for the training set\n",
        "train_predictions = []\n",
        "train_all_logits = []\n",
        "\n",
        "# Run inference on the training set using the NON-SHUFFLED loader\n",
        "print(\"Applying LeNet model to the train_dataset (using non-shuffled loader)...\")\n",
        "with torch.inference_mode(): # Disable gradient calculation\n",
        "    # Use the new train_inference_loader\n",
        "    for images, _ in tqdm(train_inference_loader, desc=\"Processing train batches for inference\"):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        logits = loaded_model(images)\n",
        "        train_all_logits.append(logits.cpu().numpy()) # Store logits\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        train_predictions.extend(predicted.cpu().numpy()) # Store predictions\n",
        "\n",
        "# Concatenate logits from all batches\n",
        "train_all_logits = np.concatenate(train_all_logits, axis=0)\n",
        "\n",
        "print(\"Inference on train_dataset complete.\")\n",
        "print(f\"Shape of collected train logits: {train_all_logits.shape}\")\n",
        "print(f\"Number of collected train predictions: {len(train_predictions)}\")\n",
        "\n",
        "# Store the predictions and logits back into the FiftyOne dataset as Classification objects\n",
        "print(\"Storing predictions and logits as FiftyOne Classifications for train_dataset...\")\n",
        "for i, sample in enumerate(tqdm(train_dataset, desc=\"Storing train classifications\")):\n",
        "    predicted_idx = train_predictions[i]\n",
        "    predicted_label = dataset_classes[predicted_idx] # Assuming dataset_classes is consistent\n",
        "    sample_logits = train_all_logits[i]\n",
        "    confidences = Fun.softmax(torch.tensor(sample_logits), dim=0).numpy()\n",
        "    predicted_confidence = float(confidences[predicted_idx])\n",
        "    classification = fo.Classification(\n",
        "        label=predicted_label,\n",
        "        confidence=predicted_confidence,\n",
        "        logits=sample_logits.tolist()\n",
        "    )\n",
        "    sample[\"lenet_train_classification\"] = classification\n",
        "    sample.save()\n",
        "\n",
        "print(\"Predictions and logits stored successfully as FiftyOne Classifications for train_dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "83271a41",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying LeNet model to the validation_dataset (using non-shuffled loader)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing validation batches for inference: 100%|██████████| 141/141 [00:01<00:00, 98.79it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference on validation_dataset complete.\n",
            "Shape of collected validation logits: (9000, 10)\n",
            "Number of collected validation predictions: 9000\n",
            "Storing predictions and logits as FiftyOne Classifications for validation_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing validation classifications: 100%|██████████| 9000/9000 [00:19<00:00, 471.07it/s]\n"
          ]
        }
      ],
      "source": [
        "# doing the same for the validation dataset\n",
        "# This uses the torch_validation_set which is derived from validation_dataset\n",
        "val_inference_loader = torch.utils.data.DataLoader(\n",
        "    torch_val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # CRITICAL: Must be False for ordered predictions\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Set the loaded model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# Lists to store predictions and logits for the validation set\n",
        "val_predictions = []\n",
        "val_all_logits = []\n",
        "\n",
        "# Run inference on the validation set using the NON-SHUFFLED loader\n",
        "print(\"Applying LeNet model to the validation_dataset (using non-shuffled loader)...\")\n",
        "with torch.inference_mode(): # Disable gradient calculation\n",
        "    # Use the new val_inference_loader\n",
        "    for images, _ in tqdm(val_inference_loader, desc=\"Processing validation batches for inference\"):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        logits = loaded_model(images)\n",
        "        val_all_logits.append(logits.cpu().numpy()) # Store logits\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        val_predictions.extend(predicted.cpu().numpy()) # Store predictions\n",
        "\n",
        "# Concatenate logits from all batches\n",
        "val_all_logits = np.concatenate(val_all_logits, axis=0)\n",
        "\n",
        "print(\"Inference on validation_dataset complete.\")\n",
        "print(f\"Shape of collected validation logits: {val_all_logits.shape}\")\n",
        "print(f\"Number of collected validation predictions: {len(val_predictions)}\")\n",
        "\n",
        "# Store the predictions and logits back into the FiftyOne dataset as Classification objects\n",
        "print(\"Storing predictions and logits as FiftyOne Classifications for validation_dataset...\")\n",
        "for i, sample in enumerate(tqdm(val_dataset, desc=\"Storing validation classifications\")):\n",
        "    predicted_idx = val_predictions[i]\n",
        "    predicted_label = dataset_classes[predicted_idx] # Assuming dataset_classes is consistent\n",
        "    sample_logits = val_all_logits[i]\n",
        "    confidences = Fun.softmax(torch.tensor(sample_logits), dim=0).numpy()\n",
        "    predicted_confidence = float(confidences[predicted_idx])\n",
        "    classification = fo.Classification(\n",
        "        label=predicted_label,\n",
        "        confidence=predicted_confidence,\n",
        "        logits=sample_logits.tolist()\n",
        "    )\n",
        "    sample[\"lenet_val_classification\"] = classification\n",
        "    sample.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef650e7",
      "metadata": {
        "id": "6ef650e7"
      },
      "source": [
        "# 2. Visualizing Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uAE-D1FtVUMG",
      "metadata": {
        "id": "uAE-D1FtVUMG"
      },
      "source": [
        "### 1.1 Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a7de34e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Extract Embeddings from LeNet Model Using PyTorch Hooks\n",
        "\n",
        "def extract_lenet_embeddings(model, dataloader, device, layer_name='fc1'):\n",
        "    \"\"\"\n",
        "    Extract embeddings from a specified layer of the LeNet model using PyTorch hooks.\n",
        "\n",
        "    Args:\n",
        "        model: Trained LeNet model\n",
        "        dataloader: PyTorch DataLoader\n",
        "        device: Device to run inference on\n",
        "        layer_name: Name of the layer to extract embeddings from\n",
        "                   Options: 'conv3', 'fc1', or 'fc2'\n",
        "\n",
        "    Returns:\n",
        "        numpy array of embeddings\n",
        "    \"\"\"\n",
        "    # Dictionary to store the embeddings\n",
        "    embeddings_dict = {}\n",
        "\n",
        "    def hook_fn(module, input, output):\n",
        "        \"\"\"Hook function to capture layer outputs\"\"\"\n",
        "        # Flatten the output if it's from conv layers\n",
        "        if len(output.shape) > 2:\n",
        "            embeddings_dict['embeddings'] = output.view(output.size(0), -1).cpu().detach()\n",
        "        else:\n",
        "            embeddings_dict['embeddings'] = output.cpu().detach()\n",
        "\n",
        "    # Register the hook on the specified layer\n",
        "    layer_map = {\n",
        "        'conv3': model.conv3,  # Shape: (batch_size, 120, 1, 1) -> flattened to (batch_size, 120)\n",
        "        'fc1': model.fc1,     # Shape: (batch_size, 84) - most common choice\n",
        "        'fc2': model.fc2      # Shape: (batch_size, 10) - final logits\n",
        "    }\n",
        "\n",
        "    if layer_name not in layer_map:\n",
        "        raise ValueError(f\"Invalid layer_name. Choose from: {list(layer_map.keys())}\")\n",
        "\n",
        "    target_layer = layer_map[layer_name]\n",
        "    hook_handle = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    all_embeddings = []\n",
        "\n",
        "    print(f\"Extracting embeddings from {layer_name} layer...\")\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, _ in tqdm(dataloader, desc=\"Processing batches\"):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward pass (hook will capture the embeddings)\n",
        "            _ = model(images)\n",
        "\n",
        "            # Store the captured embeddings\n",
        "            batch_embeddings = embeddings_dict['embeddings'].numpy()\n",
        "            all_embeddings.append(batch_embeddings)\n",
        "\n",
        "    # Remove the hook to clean up\n",
        "    hook_handle.remove()\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "\n",
        "    print(f\"Extracted embeddings shape: {final_embeddings.shape}\")\n",
        "    print(f\"Embedding dimension: {final_embeddings.shape[1]}\")\n",
        "\n",
        "    return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5c72f25a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting LeNet embeddings with proper sample ordering...\n",
            "Extracting embeddings from fc1 layer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 797/797 [00:05<00:00, 142.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted embeddings shape: (51000, 84)\n",
            "Embedding dimension: 84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract embeddings from the fc1 layer (84-dimensional representations)\n",
        "print(\"Extracting LeNet embeddings with proper sample ordering...\")\n",
        "\n",
        "lenet_train_embeddings = extract_lenet_embeddings(\n",
        "    model=loaded_model,\n",
        "    dataloader=train_inference_loader,  # ✅ Use non-shuffled loader\n",
        "    device=device,\n",
        "    layer_name='fc1'  # 84-dimensional embeddings from fully connected layer\n",
        ")\n",
        "\n",
        "# Wrap embeddings to their associated filenames ()\n",
        "train_embeddings_dict = {img_path: emb for img_path, emb in zip(torch_train_set.image_paths, lenet_train_embeddings)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "60cd833f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting LeNet embeddings with proper sample ordering...\n",
            "Extracting embeddings from fc1 layer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 141/141 [00:01<00:00, 99.41it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted embeddings shape: (9000, 84)\n",
            "Embedding dimension: 84\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract embeddings from the fc1 layer (84-dimensional representations)\n",
        "print(\"Extracting LeNet embeddings with proper sample ordering...\")\n",
        "\n",
        "lenet_val_embeddings = extract_lenet_embeddings(\n",
        "    model=loaded_model,\n",
        "    dataloader=val_inference_loader,  # ✅ Use non-shuffled loader\n",
        "    device=device,\n",
        "    layer_name='fc1'  # 84-dimensional embeddings from fully connected layer\n",
        ")\n",
        "\n",
        "# Wrap embeddings to their associated filenames ()\n",
        "val_embeddings_dict = {img_path: emb for img_path, emb in zip(torch_val_set.image_paths, lenet_val_embeddings)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "jk58xAvukI-R",
      "metadata": {
        "id": "jk58xAvukI-R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing LeNet embeddings in FiftyOne dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing embeddings: 100%|██████████| 51000/51000 [01:57<00:00, 434.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet embeddings stored successfully in samples from train_dataset.\n",
            "Sample LeNet embedding shape: (84,)\n",
            "Embedding type: <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Storing LeNet embeddings in FiftyOne dataset...\")\n",
        "\n",
        "# Store embeddings in each sample\n",
        "for index, sample in enumerate(tqdm(train_dataset, desc=\"Storing embeddings\")):\n",
        "    sample[\"lenet_embeddings\"] = lenet_train_embeddings[index]\n",
        "    sample.save()\n",
        "\n",
        "print(\"LeNet embeddings stored successfully in samples from train_dataset.\")\n",
        "\n",
        "# Verify storage\n",
        "sample = train_dataset.first()\n",
        "print(f\"Sample LeNet embedding shape: {sample.lenet_embeddings.shape}\")\n",
        "print(f\"Embedding type: {type(sample.lenet_embeddings)}\")\n",
        "\n",
        "# Persisting the change\n",
        "train_dataset.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b06ec835",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing LeNet embeddings in FiftyOne dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing embeddings: 100%|██████████| 9000/9000 [00:20<00:00, 437.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet embeddings stored successfully in samples from val_dataset.\n",
            "Sample LeNet embedding shape: (84,)\n",
            "Embedding type: <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(\"Storing LeNet embeddings in FiftyOne dataset...\")\n",
        "\n",
        "# Store embeddings in each sample\n",
        "for index, sample in enumerate(tqdm(val_dataset, desc=\"Storing embeddings\")):\n",
        "    sample[\"lenet_embeddings\"] = lenet_val_embeddings[index]\n",
        "    sample.save()\n",
        "\n",
        "print(\"LeNet embeddings stored successfully in samples from val_dataset.\")\n",
        "# Verify storage\n",
        "sample = val_dataset.first()\n",
        "print(f\"Sample LeNet embedding shape: {sample.lenet_embeddings.shape}\")\n",
        "print(f\"Embedding type: {type(sample.lenet_embeddings)}\")\n",
        "# Persisting the change\n",
        "val_dataset.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_0ZlWTseUz4t",
      "metadata": {
        "id": "_0ZlWTseUz4t"
      },
      "source": [
        "### 1.2 Show Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3GNRVi6VbZfv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "3GNRVi6VbZfv",
        "outputId": "2c8776a8-3dd6-4abe-81bb-5c44b0177d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization...\n",
            "Generating visualization...\n",
            "UMAP( verbose=True)\n",
            "Fri Nov 21 09:09:59 2025 Construct fuzzy simplicial set\n",
            "Fri Nov 21 09:09:59 2025 Finding Nearest Neighbors\n",
            "Fri Nov 21 09:09:59 2025 Building RP forest with 16 trees\n",
            "Fri Nov 21 09:10:09 2025 NN descent for 16 iterations\n",
            "\t 1  /  16\n",
            "\t 2  /  16\n",
            "\t 3  /  16\n",
            "\tStopping threshold met -- exiting after 3 iterations\n",
            "Fri Nov 21 09:10:29 2025 Finished Nearest Neighbor Search\n",
            "Fri Nov 21 09:10:34 2025 Construct embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:   2%| ▎          5/200 [00:02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  0  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  12%| █▎         25/200 [00:03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  20  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  23%| ██▎        46/200 [00:04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  40  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  32%| ███▏       64/200 [00:04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  60  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  42%| ████▏      84/200 [00:05]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  80  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  53%| █████▎     106/200 [00:06]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  100  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  62%| ██████▎    125/200 [00:07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  120  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  74%| ███████▎   147/200 [00:07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  140  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  82%| ████████▎  165/200 [00:08]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  160  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  93%| █████████▎ 186/200 [00:09]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  180  /  200 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed: 100%| ██████████ 200/200 [00:10]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Nov 21 09:10:54 2025 Finished embedding\n",
            "Generating visualization...\n",
            "Generating visualization...\n",
            "UMAP( verbose=True)\n",
            "Fri Nov 21 09:10:55 2025 Construct fuzzy simplicial set\n",
            "Fri Nov 21 09:10:55 2025 Finding Nearest Neighbors\n",
            "Fri Nov 21 09:10:55 2025 Building RP forest with 10 trees\n",
            "Fri Nov 21 09:10:55 2025 NN descent for 13 iterations\n",
            "\t 1  /  13\n",
            "\t 2  /  13\n",
            "\t 3  /  13\n",
            "\tStopping threshold met -- exiting after 3 iterations\n",
            "Fri Nov 21 09:10:56 2025 Finished Nearest Neighbor Search\n",
            "Fri Nov 21 09:10:56 2025 Construct embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:   2%| ▏          8/500 [00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  0  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  14%| █▍         71/500 [00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  50  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  24%| ██▍        119/500 [00:01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  100  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  32%| ███▏       162/500 [00:01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  150  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  45%| ████▍      223/500 [00:02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  200  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  55%| █████▍     274/500 [00:02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  250  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  65%| ██████▌    325/500 [00:02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  300  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  73%| ███████▎   363/500 [00:03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  350  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  84%| ████████▍  421/500 [00:03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  400  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  94%| █████████▎ 468/500 [00:04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  450  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed: 100%| ██████████ 500/500 [00:04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Nov 21 09:11:01 2025 Finished embedding\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<fiftyone.brain.visualization.VisualizationResults at 0x7f81eb60ced0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from umap import UMAP\n",
        "# PCA\n",
        "fob.compute_visualization(train_dataset, embeddings=lenet_train_embeddings, brain_key=\"pca_emb\", method=\"pca\")\n",
        "# UMAP\n",
        "fob.compute_visualization(train_dataset, embeddings=lenet_train_embeddings, brain_key=\"umap_emb\", method=\"umap\")\n",
        "\n",
        "# PCA\n",
        "fob.compute_visualization(val_dataset, embeddings=lenet_val_embeddings, brain_key=\"pca_emb\", method=\"pca\")\n",
        "# UMAP\n",
        "fob.compute_visualization(val_dataset, embeddings=lenet_val_embeddings, brain_key=\"umap_emb\", method=\"umap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "wVwefev-XqdH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVwefev-XqdH",
        "outputId": "4d0d47e0-fd97-41d1-faa5-5eb01fb08f38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Panel: {\n",
              "    'component_id': '0c3f88a7-cf1e-40e9-a8cb-f0b2e6d0685e',\n",
              "    'type': 'Embeddings',\n",
              "    'pinned': False,\n",
              "    'state': {'brainResult': 'umap_emb', 'colorByField': 'ground_truth.label'},\n",
              "}>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fo.Panel(\n",
        "    type=\"Embeddings\",\n",
        "    state=dict(brainResult=\"pca_emb\", colorByField=\"ground_truth.label\"),\n",
        ")\n",
        "fo.Panel(\n",
        "    type=\"Embeddings\",\n",
        "    state=dict(brainResult=\"umap_emb\", colorByField=\"ground_truth.label\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ORcdrQGyVDg6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "collapsed": true,
        "id": "ORcdrQGyVDg6",
        "outputId": "6ead4f84-24ec-4236-a227-198ac6d44fd9"
      },
      "outputs": [],
      "source": [
        "session.dataset=val_dataset\n",
        "session.refresh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "UPVDcym3g8IS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPVDcym3g8IS",
        "outputId": "0185be62-e47e-44c4-9195-d86bbf34b1d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA Outliers: ['/home/linus/fiftyone/mnist/train/data/000081.jpg', '/home/linus/fiftyone/mnist/train/data/000658.jpg', '/home/linus/fiftyone/mnist/train/data/002323.jpg', '/home/linus/fiftyone/mnist/train/data/002677.jpg', '/home/linus/fiftyone/mnist/train/data/003291.jpg', '/home/linus/fiftyone/mnist/train/data/005639.jpg', '/home/linus/fiftyone/mnist/train/data/005719.jpg', '/home/linus/fiftyone/mnist/train/data/006093.jpg', '/home/linus/fiftyone/mnist/train/data/006327.jpg', '/home/linus/fiftyone/mnist/train/data/007011.jpg', '/home/linus/fiftyone/mnist/train/data/007265.jpg', '/home/linus/fiftyone/mnist/train/data/007910.jpg', '/home/linus/fiftyone/mnist/train/data/008905.jpg', '/home/linus/fiftyone/mnist/train/data/010832.jpg', '/home/linus/fiftyone/mnist/train/data/011105.jpg', '/home/linus/fiftyone/mnist/train/data/011712.jpg', '/home/linus/fiftyone/mnist/train/data/011939.jpg', '/home/linus/fiftyone/mnist/train/data/012809.jpg', '/home/linus/fiftyone/mnist/train/data/014223.jpg', '/home/linus/fiftyone/mnist/train/data/016489.jpg', '/home/linus/fiftyone/mnist/train/data/017092.jpg', '/home/linus/fiftyone/mnist/train/data/017215.jpg', '/home/linus/fiftyone/mnist/train/data/017541.jpg', '/home/linus/fiftyone/mnist/train/data/017740.jpg', '/home/linus/fiftyone/mnist/train/data/019361.jpg', '/home/linus/fiftyone/mnist/train/data/023887.jpg', '/home/linus/fiftyone/mnist/train/data/023912.jpg', '/home/linus/fiftyone/mnist/train/data/024799.jpg', '/home/linus/fiftyone/mnist/train/data/026377.jpg', '/home/linus/fiftyone/mnist/train/data/026561.jpg', '/home/linus/fiftyone/mnist/train/data/026627.jpg', '/home/linus/fiftyone/mnist/train/data/027469.jpg', '/home/linus/fiftyone/mnist/train/data/027615.jpg', '/home/linus/fiftyone/mnist/train/data/028655.jpg', '/home/linus/fiftyone/mnist/train/data/030453.jpg', '/home/linus/fiftyone/mnist/train/data/030752.jpg', '/home/linus/fiftyone/mnist/train/data/031728.jpg', '/home/linus/fiftyone/mnist/train/data/032857.jpg', '/home/linus/fiftyone/mnist/train/data/032859.jpg', '/home/linus/fiftyone/mnist/train/data/033507.jpg', '/home/linus/fiftyone/mnist/train/data/034751.jpg', '/home/linus/fiftyone/mnist/train/data/035465.jpg', '/home/linus/fiftyone/mnist/train/data/036032.jpg', '/home/linus/fiftyone/mnist/train/data/037681.jpg', '/home/linus/fiftyone/mnist/train/data/037751.jpg', '/home/linus/fiftyone/mnist/train/data/038398.jpg', '/home/linus/fiftyone/mnist/train/data/039379.jpg', '/home/linus/fiftyone/mnist/train/data/039428.jpg', '/home/linus/fiftyone/mnist/train/data/040077.jpg', '/home/linus/fiftyone/mnist/train/data/040281.jpg', '/home/linus/fiftyone/mnist/train/data/040825.jpg', '/home/linus/fiftyone/mnist/train/data/040977.jpg', '/home/linus/fiftyone/mnist/train/data/041055.jpg', '/home/linus/fiftyone/mnist/train/data/041206.jpg', '/home/linus/fiftyone/mnist/train/data/041397.jpg', '/home/linus/fiftyone/mnist/train/data/042416.jpg', '/home/linus/fiftyone/mnist/train/data/044263.jpg', '/home/linus/fiftyone/mnist/train/data/044899.jpg', '/home/linus/fiftyone/mnist/train/data/046067.jpg', '/home/linus/fiftyone/mnist/train/data/046299.jpg', '/home/linus/fiftyone/mnist/train/data/047763.jpg', '/home/linus/fiftyone/mnist/train/data/048071.jpg', '/home/linus/fiftyone/mnist/train/data/049516.jpg', '/home/linus/fiftyone/mnist/train/data/049845.jpg', '/home/linus/fiftyone/mnist/train/data/050341.jpg', '/home/linus/fiftyone/mnist/train/data/050460.jpg', '/home/linus/fiftyone/mnist/train/data/050573.jpg', '/home/linus/fiftyone/mnist/train/data/050633.jpg', '/home/linus/fiftyone/mnist/train/data/050897.jpg', '/home/linus/fiftyone/mnist/train/data/051281.jpg', '/home/linus/fiftyone/mnist/train/data/052739.jpg', '/home/linus/fiftyone/mnist/train/data/052915.jpg', '/home/linus/fiftyone/mnist/train/data/054037.jpg', '/home/linus/fiftyone/mnist/train/data/057663.jpg', '/home/linus/fiftyone/mnist/train/data/057701.jpg', '/home/linus/fiftyone/mnist/train/data/059720.jpg', '/home/linus/fiftyone/mnist/train/data/059834.jpg']\n",
            "UMAP Outliers: []\n"
          ]
        }
      ],
      "source": [
        "pca_outliers = [sample.filepath for sample in train_dataset if \"pca_outliers\" in sample.tags]\n",
        "umap_outliers = [sample.filepath for sample in train_dataset if \"umap_outliers\" in sample.tags]\n",
        "print(f\"PCA Outliers: {pca_outliers}\"\n",
        "      )\n",
        "print(f\"UMAP Outliers: {umap_outliers}\"\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bff7911f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/home/linus/fiftyone/mnist/train/data/000213.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/001941.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/002555.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/003908.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/004201.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/008221.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/010065.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/010242.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/010283.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/011670.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/012273.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/014143.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/016699.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/018509.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/019307.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/020919.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/021303.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/022482.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/023869.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/024992.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/025679.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/026224.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/026623.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/026731.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/027557.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/028052.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/028117.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/028711.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/029181.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/033305.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/035014.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/035311.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/035599.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/037835.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/042113.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/043186.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/048229.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/048615.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/049899.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/049961.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/050523.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/051249.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/052517.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/053064.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/053397.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/054265.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/054918.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/054976.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/055731.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/057710.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/058345.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/058872.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/059702.jpg'\n",
            "\n",
            "'/home/linus/fiftyone/mnist/train/data/059767.jpg'\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pca_outliers = [sample.filepath for sample in val_dataset if \"pca_outliers\" in sample.tags]\n",
        "umap_outliers = [sample.filepath for sample in val_dataset if \"umap_outliers\" in sample.tags]\n",
        "for outlier in pca_outliers:\n",
        "    print(f\"'{outlier}',\")\n",
        "print(\"\\n\\n\")\n",
        "for outlier in umap_outliers:\n",
        "    print(f\"'{outlier}',\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82e2c04",
      "metadata": {},
      "source": [
        "### 2.3 Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e7534f56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77 samples found\n"
          ]
        }
      ],
      "source": [
        "# with manual inspection of the outliers in the PCA embedding space, I found the following faulty samples:\n",
        "train_pca_outliers = set(['/home/linus/fiftyone/mnist/train/data/000081.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/000658.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/002323.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/002677.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/003291.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/005639.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/005719.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/006093.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/006327.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/007011.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/007265.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/007910.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/008905.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/010832.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/011105.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/011712.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/011939.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/012809.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/014223.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/016489.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/017092.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/017215.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/017541.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/017740.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/019361.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/023887.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/023912.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/024799.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/026377.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/026561.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/026627.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/027469.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/027615.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/028655.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/030453.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/030752.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/031728.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/032857.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/032859.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/033507.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/034751.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/035465.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/036032.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/037681.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/037751.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/038398.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/039379.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/039428.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/040077.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/040281.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/040825.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/040977.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/041055.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/041206.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/041397.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/042416.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/044263.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/044899.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/046067.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/046299.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/047763.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/048071.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/049516.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/049845.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/050341.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/050460.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/050573.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/050633.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/050897.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/051281.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/052739.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/052915.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/054037.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/057663.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/057701.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/059720.jpg',\n",
        "                          '/home/linus/fiftyone/mnist/train/data/059834.jpg'])\n",
        "print(f\"{len(train_pca_outliers)} samples found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "03a650a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54 samples found\n"
          ]
        }
      ],
      "source": [
        "# with manual inspection of the outliers in the PCA embedding space, I found the following faulty samples:\n",
        "val_pca_outliers = set([\n",
        "'/home/linus/fiftyone/mnist/train/data/000213.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/001941.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/002555.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/003908.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/004201.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/008221.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/010065.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/010242.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/010283.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/011670.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/012273.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/014143.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/016699.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/018509.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/019307.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/020919.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/021303.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/022482.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/023869.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/024992.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/025679.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026224.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026623.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026731.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/027557.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/028052.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/028117.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/028711.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/029181.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/033305.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035014.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035311.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035599.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/037835.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/042113.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/043186.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/048229.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/048615.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/049899.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/049961.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/050523.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/051249.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/052517.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/053064.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/053397.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/054265.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/054918.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/054976.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/055731.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/057710.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/058345.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/058872.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/059702.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/059767.jpg'\n",
        "])\n",
        "print(f\"{len(val_pca_outliers)} samples found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nu8Xwul0TQIS",
      "metadata": {
        "id": "Nu8Xwul0TQIS"
      },
      "source": [
        "# 3. Curating the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JFRP06l7eJv_",
      "metadata": {
        "id": "JFRP06l7eJv_"
      },
      "source": [
        "## 3.1 Apply Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "edf55272",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying LeNet model to the train_val_dataset (using non-shuffled loader)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing train_val batches for inference: 100%|██████████| 938/938 [00:06<00:00, 149.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference on train_dataset complete.\n",
            "Shape of collected train logits: (60000, 10)\n",
            "Number of collected train predictions: 60000\n",
            "Storing predictions and logits as FiftyOne Classifications for train_val_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing train_val classifications: 100%|██████████| 60000/60000 [02:03<00:00, 484.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions and logits stored successfully as FiftyOne Classifications for train_val_dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch_train_val_set = CustomTorchImageDataset(\n",
        "    train_val_dataset,\n",
        "    label_map=label_map,\n",
        "    image_transforms=image_transforms\n",
        ")\n",
        "\n",
        "# This uses the torch_train_val_set which is derived from train_val_dataset\n",
        "train_val_inference_loader = torch.utils.data.DataLoader(\n",
        "    torch_train_val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # CRITICAL: Must be False for ordered predictions\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Set the loaded model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# Lists to store predictions and logits for the training set\n",
        "train_val_predictions = []\n",
        "train_val_all_logits = []\n",
        "\n",
        "# Run inference on the training set using the NON-SHUFFLED loader\n",
        "print(\"Applying LeNet model to the train_val_dataset (using non-shuffled loader)...\")\n",
        "with torch.inference_mode(): # Disable gradient calculation\n",
        "    # Use the new train_val_inference_loader\n",
        "    for images, _ in tqdm(train_val_inference_loader, desc=\"Processing train_val batches for inference\"):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        logits = loaded_model(images)\n",
        "        train_val_all_logits.append(logits.cpu().numpy()) # Store logits\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        train_val_predictions.extend(predicted.cpu().numpy()) # Store predictions\n",
        "# Concatenate logits from all batches\n",
        "train_val_all_logits = np.concatenate(train_val_all_logits, axis=0)\n",
        "\n",
        "print(\"Inference on train_dataset complete.\")\n",
        "print(f\"Shape of collected train logits: {train_val_all_logits.shape}\")\n",
        "print(f\"Number of collected train predictions: {len(train_val_predictions)}\")\n",
        "\n",
        "# Store the predictions and logits back into the FiftyOne dataset as Classification objects\n",
        "print(\"Storing predictions and logits as FiftyOne Classifications for train_val_dataset...\")\n",
        "for i, sample in enumerate(tqdm(train_val_dataset, desc=\"Storing train_val classifications\")):\n",
        "    predicted_idx = train_val_predictions[i]\n",
        "    predicted_label = dataset_classes[predicted_idx] # Assuming dataset_classes is consistent\n",
        "    sample_logits = train_val_all_logits[i]\n",
        "    confidences = Fun.softmax(torch.tensor(sample_logits), dim=0).numpy()\n",
        "    predicted_confidence = float(confidences[predicted_idx])\n",
        "    classification = fo.Classification(\n",
        "        label=predicted_label,\n",
        "        confidence=predicted_confidence,\n",
        "        logits=sample_logits.tolist()\n",
        "    )\n",
        "    sample[\"lenet_train_val_classification\"] = classification\n",
        "    sample.save()\n",
        "\n",
        "print(\"Predictions and logits stored successfully as FiftyOne Classifications for train_val_dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dHUyUDU1eDOi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "dHUyUDU1eDOi",
        "outputId": "8c766f49-af05-48b7-cd5e-100470ffbd07"
      },
      "outputs": [],
      "source": [
        "lenet_train_val_evaluation_results = train_val_dataset.evaluate_classifications(\n",
        "    \"lenet_train_val_classification\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"lenet_train_val_eval\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bzic-_4eHkp",
      "metadata": {
        "id": "9bzic-_4eHkp"
      },
      "source": [
        "## 3.1 use hardness and mistakeness\n",
        "### 3.1.1 Hardness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "BvK0bwvGFwHV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvK0bwvGFwHV",
        "outputId": "1d2adca8-5333-4c52-a36f-03a47b687108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing mistakenness...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 60000/60000 [2.3m elapsed, 0s remaining, 478.3 samples/s]      \n",
            "Mistakenness computation complete\n"
          ]
        }
      ],
      "source": [
        "fob.compute_mistakenness(train_val_dataset,\n",
        "                         pred_field=\"lenet_train_val_classification\",\n",
        "                         label_field=\"ground_truth\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "q_6-9nu4VFHT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_6-9nu4VFHT",
        "outputId": "ce566aec-281c-4d83-c151-81229c413c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing hardness...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 60000/60000 [2.6m elapsed, 0s remaining, 395.4 samples/s]      \n",
            "Hardness computation complete\n"
          ]
        }
      ],
      "source": [
        "fob.compute_hardness(train_val_dataset, label_field='lenet_train_val_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "_dVOKuvaMutU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dVOKuvaMutU",
        "outputId": "f4487ce9-3612-46fa-84a0-2331a5c1a715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of highly mistaken samples (top 1%): 60\n",
            "Number of highly hard samples (top 1%): 60\n",
            "Total number of difficult samples (union of highly mistaken and highly hard): 120\n"
          ]
        }
      ],
      "source": [
        "# Identify samples in the top 0.1 percentile of mistakenness (likely annotation errors)mistakenness_99th_percentile = train_dataset.quantiles(\"mistakenness\", [0.99])[0]\n",
        "mistakenness_99th_percentile = train_val_dataset.quantiles(\"mistakenness\", [0.999])[0]\n",
        "highly_mistaken_view = train_val_dataset.match(F(\"mistakenness\") > mistakenness_99th_percentile)\n",
        "\n",
        "# Identify samples in the top 1 percentile of hardness (likely genuinely hard samples)\n",
        "hardness_99th_percentile = train_val_dataset.quantiles(\"hardness\", [0.999])[0]\n",
        "highly_hard_view = train_val_dataset.match(F(\"hardness\") > hardness_99th_percentile)\n",
        "\n",
        "print(f\"Number of highly mistaken samples (top 1%): {len(highly_mistaken_view)}\")\n",
        "print(f\"Number of highly hard samples (top 1%): {len(highly_hard_view)}\")\n",
        "\n",
        "# Get the IDs of samples that are highly mistaken or highly hard\n",
        "highly_mistaken_ids = set(highly_mistaken_view.values(\"id\"))\n",
        "highly_hard_ids = set(highly_hard_view.values(\"id\"))\n",
        "\n",
        "# Combine the sets of IDs that are hard\n",
        "difficult_samples = highly_mistaken_ids.union(highly_hard_ids)\n",
        "\n",
        "print(f\"Total number of difficult samples (union of highly mistaken and highly hard): {len(difficult_samples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f6b35ac2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mistakenness 99.9th percentile threshold: 0.9941620230674744\n",
            "hardness 99.9th percentile threshold: 1.6354171375013595\n"
          ]
        }
      ],
      "source": [
        "print(f\"mistakenness 99.9th percentile threshold: {mistakenness_99th_percentile}\")\n",
        "print(f\"hardness 99.9th percentile threshold: {hardness_99th_percentile}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fbd2393b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# manually inspect the difficult samples\n",
        "difficult_view = train_val_dataset.match(F(\"id\").is_in(difficult_samples))\n",
        "session.view = difficult_view\n",
        "session.refresh()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xgD8Nmbbn7am",
      "metadata": {
        "id": "xgD8Nmbbn7am"
      },
      "source": [
        "## 3.2 Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "Bmtp2ijxPl5s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmtp2ijxPl5s",
        "outputId": "3705e61b-4048-4805-dcef-89c532ad428d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/home/linus/fiftyone/mnist/train/data/000495.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/000903.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/001048.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/002555.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/003999.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/005719.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/007081.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/007265.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/010065.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/012184.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/014583.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/016131.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/018229.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/019361.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/024588.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/025160.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/025563.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/025679.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/026623.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/026627.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/026749.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/027557.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/030050.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/032343.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/035235.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/035617.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/036447.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/037469.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/037681.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/038878.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/039185.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/040145.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/040281.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/041898.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/042567.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/043110.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/043455.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/043659.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/044263.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/049961.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/050240.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/051249.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/053217.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/053397.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/057663.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/057745.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/059916.jpg',\n"
          ]
        }
      ],
      "source": [
        "# save filenames to drive\n",
        "high_mistakenness_filenames = [sample.filepath for sample in train_val_dataset if \"mistaken\" in sample.tags]\n",
        "for filename in high_mistakenness_filenames:\n",
        "    print(f\"'{filename}',\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "454efc6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/home/linus/fiftyone/mnist/train/data/000081.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/001513.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/003291.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/003393.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/005333.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/006348.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/008762.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/009257.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/016377.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/016677.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/017130.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/017707.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/020170.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/025547.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/027707.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/028358.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/031198.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/031311.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/033507.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/034666.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/034708.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/034862.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/034921.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/035247.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/036654.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/037063.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/039356.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/040467.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/041219.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/045503.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/046016.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/046241.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/048976.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/054037.jpg',\n",
            "'/home/linus/fiftyone/mnist/train/data/056398.jpg',\n"
          ]
        }
      ],
      "source": [
        "# save filenames to drive\n",
        "high_mistakenness_filenames = [sample.filepath for sample in train_val_dataset if \"hard\" in sample.tags]\n",
        "for filename in high_mistakenness_filenames:\n",
        "    print(f\"'{filename}',\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e3a0444b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# with manual inspection of the samples with high mistakenness scores, I found the following mislabeled or unusable samples:\n",
        "high_mistakenness = set([\n",
        "'/home/linus/fiftyone/mnist/train/data/000495.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/000903.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/001048.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/002555.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/003999.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/005719.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/007081.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/007265.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/010065.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/012184.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/014583.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/016131.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/018229.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/019361.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/024588.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/025160.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/025563.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/025679.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026623.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026627.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/026749.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/027557.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/030050.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/032343.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035235.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035617.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/036447.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/037469.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/037681.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/038878.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/039185.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/040145.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/040281.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/041898.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/042567.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/043110.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/043455.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/043659.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/044263.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/049961.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/050240.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/051249.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/053217.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/053397.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/057663.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/057745.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/059916.jpg',\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9c56e6c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# with manual inspection of the samples with high hardness scores, I found the following genuinely mislabled or unusable samples:\n",
        "high_hardness = set([\n",
        "'/home/linus/fiftyone/mnist/train/data/000081.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/001513.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/003291.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/003393.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/005333.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/006348.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/008762.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/009257.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/016377.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/016677.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/017130.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/017707.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/020170.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/025547.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/027707.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/028358.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/031198.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/031311.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/033507.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/034666.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/034708.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/034862.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/034921.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/035247.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/036654.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/037063.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/039356.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/040467.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/041219.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/045503.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/046016.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/046241.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/048976.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/054037.jpg',\n",
        "'/home/linus/fiftyone/mnist/train/data/056398.jpg',\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bb911621",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of difficult samples after manual inspection: 193\n"
          ]
        }
      ],
      "source": [
        "combined_difficult_samples = high_mistakenness.union(high_hardness).union(train_pca_outliers).union(val_pca_outliers)\n",
        "print(f\"Total number of difficult samples after manual inspection: {len(combined_difficult_samples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8__89QLprZ8D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "538b843eb3d04f3a92158a7e56873500",
            "32a3cd6e01f44498a2eab8004cd1fc68",
            "f7dbc1749aca4b81bb145c9612f399f2",
            "201bcac0fce44f96945bc86243c3b51c",
            "466698f9b1104e81ada86cd60650d9d6",
            "1355d0e7ccca4c64b769b00aff29d84d",
            "6524ac0a3aae46488b4ef9e2c4767d6b",
            "1ee7b2d5802f4a5bb25439e6619f8b7a",
            "8ba3c9ed82974d55945db76b8a65d5f4",
            "32ac3c35b6f04082961e28bc9c7bde6e",
            "200f12c50f09419781eb83b624d88d68",
            "818a672533e143d88e53754cf21508fb",
            "5b0f527eec5b4b5e91468413849f9fd0",
            "68153618c121498f94bb16ee795c85d6",
            "d5a83cfd591941d697c1c35c029359c9",
            "d38390d2d634415ab0abdea74b4523d4",
            "b31d9dfe084844f09d6727ceccbcb519"
          ]
        },
        "id": "8__89QLprZ8D",
        "outputId": "08871d04-3a26-4410-b034-71e98eeafb8b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538b843eb3d04f3a92158a7e56873500",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pushing dataset to Hugging Face Hub: mnist-cleaned-up\n",
            "Directory '/tmp/tmpi_64b8t1' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fiftyone.core.collections:Directory '/tmp/tmpi_64b8t1' already exists; export will be merged with existing files\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.data.exporters:Exporting samples...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |████████████████████| 505/505 [148.5ms elapsed, 0s remaining, 3.4K docs/s]     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |████████████████████| 505/505 [148.5ms elapsed, 0s remaining, 3.4K docs/s]     \n",
            "Uploading media files:   0%|          | 0/1 [00:00<?, ?it/s]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "WARNING:huggingface_hub.hf_api:It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files: 100%|██████████| 1/1 [00:15<00:00, 15.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'mnist-cleaned-up' successfully pushed to Hugging Face Hub!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hf_data_set =\n",
        "hf_dataset_name = \"mnist-cleaned-up\"\n",
        "\n",
        "print(f\"\\nPushing dataset to Hugging Face Hub: {hf_dataset_name}\")\n",
        "fouh.push_to_hub(new_train_dataset, hf_dataset_name)\n",
        "\n",
        "print(f\"Dataset '{hf_dataset_name}' successfully pushed to Hugging Face Hub!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CJsvXALKV5RD",
      "metadata": {
        "id": "CJsvXALKV5RD"
      },
      "source": [
        "# 4. classifier with IDK class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iQ82duzYxQIr",
      "metadata": {
        "id": "iQ82duzYxQIr"
      },
      "source": [
        "## 4.1 Defining the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XXdPU-XkxQIs",
      "metadata": {
        "id": "XXdPU-XkxQIs"
      },
      "source": [
        "### Model Architecure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "qP4jw8wBxQIt",
      "metadata": {
        "id": "qP4jw8wBxQIt"
      },
      "outputs": [],
      "source": [
        "class NewModernLeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super(NewModernLeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=4)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.relu(self.conv3(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wc5LzrVnxQIv",
      "metadata": {
        "id": "Wc5LzrVnxQIv"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "Nni8_gS3Mfdj",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nni8_gS3Mfdj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset sizes: train=51000, val=9000, test=10000\n"
          ]
        }
      ],
      "source": [
        "new_train_dataset = train_dataset.clone()\n",
        "new_val_dataset = val_dataset.clone()\n",
        "new_test_dataset = test_dataset.clone()\n",
        "print(f\"Dataset sizes: train={len(new_train_dataset)}, val={len(new_val_dataset)}, test={len(new_test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "iQ1olCXZfD1V",
      "metadata": {
        "id": "iQ1olCXZfD1V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "123 samples to exclude from train dataset\n",
            "70 samples to exclude from val dataset\n"
          ]
        }
      ],
      "source": [
        "exclude_samples_train = train_dataset.match(\n",
        "    fo.ViewField(\"filepath\").is_in(combined_difficult_samples))\n",
        "exclude_samples_val = val_dataset.match(\n",
        "    fo.ViewField(\"filepath\").is_in(combined_difficult_samples))\n",
        "print(f\"{len(exclude_samples_train)} samples to exclude from train dataset\")\n",
        "print(f\"{len(exclude_samples_val)} samples to exclude from val dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "X584bmyoL1N6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X584bmyoL1N6",
        "outputId": "ba5c9bfd-feac-4ad7-88aa-bbae96390156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labeled 123 samples with 'idontknow' in train set\n",
            "labeled 70 samples with 'idontknow' in validation set\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "\n",
        "excluded_train_ids = set(exclude_samples_train.values(\"id\"))\n",
        "\n",
        "for sample in new_train_dataset:\n",
        "    if sample.id in excluded_train_ids:\n",
        "        sample.ground_truth.label = \"idontknow\"\n",
        "        sample.save()\n",
        "        count = count + 1\n",
        "print(f\"labeled {count} samples with 'idontknow' in train set\")\n",
        "\n",
        "excluded_val_ids = set(exclude_samples_val.values(\"id\"))\n",
        "count = 0\n",
        "for sample in new_val_dataset:\n",
        "    if sample.id in excluded_val_ids:\n",
        "        sample.ground_truth.label = \"idontknow\"\n",
        "        sample.save()\n",
        "        count = count + 1\n",
        "print(f\"labeled {count} samples with 'idontknow' in validation set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "049ab129",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51000\n",
            "9000\n"
          ]
        }
      ],
      "source": [
        "print(len(new_train_dataset))\n",
        "print(len(new_val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "hfYREaqpxQIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfYREaqpxQIw",
        "outputId": "e10c98ad-c1f9-4fbc-95c7-5d14b85ce9d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9,\n",
              " 'idontknow': 10}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_classes = sorted(new_train_dataset.distinct(\"ground_truth.label\"))\n",
        "new_label_map = {string_label: index for index, string_label in enumerate(new_classes)}\n",
        "new_label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "4GOUPCHFxQIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "4GOUPCHFxQIw",
        "outputId": "7151f3f2-b399-4bdb-d0b7-eab62419f857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing image intensity statistics from FiftyOne view...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51000/51000 [00:14<00:00, 3576.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed from 51000 images\n",
            "Total pixels: 39,984,000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Mean: 0.1318, Std: 0.3075'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_intensity, std_intensity = compute_stats_fiftyone(new_train_dataset)\n",
        "f\"Mean: {mean_intensity:.4f}, Std: {std_intensity:.4f}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "G3JzJUmpxQIx",
      "metadata": {
        "id": "G3JzJUmpxQIx"
      },
      "outputs": [],
      "source": [
        "image_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize((mean_intensity,), (std_intensity,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc13d923",
      "metadata": {},
      "source": [
        "### Augmentation\n",
        "because the number of problematic samples is pretty low, we need to augment them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "0ec98532",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AugmentedMNISTDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch dataset that applies augmentations to misclassified MNIST samples.\n",
        "    Each sample can be augmented multiple times to create more training data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fiftyone_view,\n",
        "                 label_map,\n",
        "                 base_transforms,\n",
        "                 augmentations=None,\n",
        "                 augment_factor=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            fiftyone_view: FiftyOne view of misclassified samples\n",
        "            label_map: Mapping from string labels to indices\n",
        "            base_transforms: Base PyTorch transforms (normalization, etc.)\n",
        "            augmentations: Albumentations transform pipeline\n",
        "            augment_factor: How many augmented versions to create per sample\n",
        "        \"\"\"\n",
        "        self.image_paths = fiftyone_view.values(\"filepath\")\n",
        "        self.str_labels = fiftyone_view.values(\"ground_truth.label\")\n",
        "        self.label_map = label_map\n",
        "        self.base_transforms = base_transforms\n",
        "        self.augmentations = augmentations\n",
        "        self.augment_factor = augment_factor\n",
        "\n",
        "        print(f\"AugmentedMNISTDataset: {len(self.image_paths)} base samples\")\n",
        "        print(f\"With augmentation factor {augment_factor}: {len(self)} total samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths) * (self.augment_factor + 1)  # +1 for original\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Determine which base sample and whether to augment\n",
        "        base_idx = idx // (self.augment_factor + 1)\n",
        "        aug_idx = idx % (self.augment_factor + 1)\n",
        "\n",
        "        # Load image\n",
        "        image_path = self.image_paths[base_idx]\n",
        "        image = Image.open(image_path).convert('L')\n",
        "\n",
        "        # Convert to numpy for albumentations\n",
        "        image_np = np.array(image, dtype=np.uint8)\n",
        "\n",
        "        # Apply augmentation if not the first version (original)\n",
        "        if aug_idx > 0 and self.augmentations is not None:\n",
        "            augmented = self.augmentations(image=image_np)\n",
        "            image_np = augmented['image']\n",
        "\n",
        "        # Convert back to PIL for PyTorch transforms\n",
        "        image = Image.fromarray(image_np).convert(\"L\")\n",
        "\n",
        "        # Apply base transforms (normalization, tensor conversion)\n",
        "        if self.base_transforms:\n",
        "            image = self.base_transforms(image)\n",
        "\n",
        "        # Get label\n",
        "        label_str = self.str_labels[base_idx]\n",
        "        label_idx = self.label_map.get(label_str, -1)\n",
        "\n",
        "        return image, torch.tensor(label_idx, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "1b470d6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'train-augment' already exists. Deleting it.\n"
          ]
        }
      ],
      "source": [
        "dataset_name = \"train-augment\"\n",
        "\n",
        "if dataset_name in fo.list_datasets():\n",
        "    print(f\"Dataset '{dataset_name}' already exists. Deleting it.\")\n",
        "    fo.delete_dataset(dataset_name)\n",
        "\n",
        "# Always create a new dataset after deleting or if it didn't exist\n",
        "train_augment = fo.Dataset(dataset_name)\n",
        "\n",
        "for sample in exclude_samples_train:\n",
        "    train_augment.add_sample(sample)\n",
        "\n",
        "train_augment.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "a18856bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "mnist_augmentations_1 = A.Compose([\n",
        "\n",
        "    # Use Affine transform for shifting, scaling, and rotating\n",
        "    A.Affine(\n",
        "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},  # ±10% translation\n",
        "        scale=(0.9, 1.1),     # ±10% scaling\n",
        "        rotate=(-5, 5),     # ±5° rotation\n",
        "        p=0.8\n",
        "    ),\n",
        "\n",
        "    # Elastic deformations to simulate handwriting style variations\n",
        "    A.ElasticTransform(\n",
        "        alpha=20,             # Strength of distortion\n",
        "        sigma=5,              # Smoothness of distortion\n",
        "        border_mode=cv2.BORDER_CONSTANT,\n",
        "        p=0.6\n",
        "    ),\n",
        "\n",
        "    # Mild perspective transformations\n",
        "    A.Perspective(scale=(0.01, 0.03), p=0.2),\n",
        "\n",
        "    # Mild grid distortion\n",
        "    A.GridDistortion(num_steps=2, distort_limit=0.05, p=0.2),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "d6817ae4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AugmentedMNISTDataset: 123 base samples\n",
            "With augmentation factor 39: 4920 total samples\n"
          ]
        }
      ],
      "source": [
        "torch_augmented_train_dataset = AugmentedMNISTDataset(\n",
        "    train_augment,\n",
        "    label_map=new_label_map,\n",
        "    base_transforms=image_transforms,\n",
        "    augmentations=mnist_augmentations_1,\n",
        "    augment_factor=39  # Create this number of augmented versions per input sample\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "UE4-nexxxQIx",
      "metadata": {
        "id": "UE4-nexxxQIx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset size: 55920\n"
          ]
        }
      ],
      "source": [
        "# Combine the original dataset with its augmentation\n",
        "combined_dataset = ConcatDataset([new_torch_train_set, torch_augmented_train_dataset])\n",
        "print(f\"Combined dataset size: {len(combined_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "542Lo9R9xQIy",
      "metadata": {
        "id": "542Lo9R9xQIy"
      },
      "outputs": [],
      "source": [
        "new_torch_val_set = CustomTorchImageDataset(new_val_dataset,\n",
        "                                     label_map=new_label_map,\n",
        "                                     image_transforms=image_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M10WnMABxQIy",
      "metadata": {
        "id": "M10WnMABxQIy"
      },
      "source": [
        "### data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "rC97BpMjxQIz",
      "metadata": {
        "id": "rC97BpMjxQIz"
      },
      "outputs": [],
      "source": [
        "# Define batch size (you can adjust this based on your GPU memory)\n",
        "batch_size = 64\n",
        "num_workers = os.cpu_count()  # Number of CPU cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "4MXcIGlExQIz",
      "metadata": {
        "id": "4MXcIGlExQIz"
      },
      "outputs": [],
      "source": [
        "new_train_loader = create_deterministic_training_dataloader(\n",
        "    combined_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "mdCDhfpYxQI0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdCDhfpYxQI0",
        "outputId": "cd58d783-7801-4234-efa5-bb3986b2efc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and validation DataLoaders created successfully.\n",
            "Train DataLoader has 874 batches.\n",
            "Validation DataLoader has 141 batches.\n"
          ]
        }
      ],
      "source": [
        "new_val_loader = torch.utils.data.DataLoader(\n",
        "    new_torch_val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Train and validation DataLoaders created successfully.\")\n",
        "print(f\"Train DataLoader has {len(new_train_loader)} batches.\")\n",
        "print(f\"Validation DataLoader has {len(new_val_loader)} batches.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UrYdjEF6xQI0",
      "metadata": {
        "id": "UrYdjEF6xQI0"
      },
      "source": [
        "### Loss-Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "avVADCQ_xQI0",
      "metadata": {
        "id": "avVADCQ_xQI0"
      },
      "outputs": [],
      "source": [
        "ce_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "av7G92YRxQI0",
      "metadata": {
        "id": "av7G92YRxQI0"
      },
      "source": [
        "### define model and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "d33hBLV-xQI1",
      "metadata": {
        "id": "d33hBLV-xQI1"
      },
      "outputs": [],
      "source": [
        "model = NewModernLeNet5().to(device)\n",
        "\n",
        "# Define the optimizer (variant of stochastic gradient descent)\n",
        "optimizer = Adam(model.parameters(),\n",
        "                 lr=0.003, betas=(0.9, 0.999),\n",
        "                 eps=1e-08, weight_decay=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7_D_QGSVxQI1",
      "metadata": {
        "id": "7_D_QGSVxQI1"
      },
      "source": [
        "### train and validate methodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "dxu-SXRqxQI1",
      "metadata": {
        "id": "dxu-SXRqxQI1"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader):\n",
        "  batch_losses = []\n",
        "  model.train()\n",
        "  for images, labels in tqdm(train_loader, desc=\"Training: \"):\n",
        "      #import pdb; pdb.set_trace()\n",
        "\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Forward pass\n",
        "      logits = model(images)\n",
        "      loss_value = ce_loss(logits, labels)\n",
        "      # Clear gradients from previous iteration (PyTorch accumulates by default)\n",
        "      optimizer.zero_grad()\n",
        "      # Computes the gradients with backpropagation\n",
        "      loss_value.backward()\n",
        "      # Updates the weights\n",
        "      optimizer.step()\n",
        "\n",
        "      batch_losses.append(loss_value.item())\n",
        "\n",
        "  train_loss = np.mean(batch_losses)\n",
        "  return train_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "k6Rr62ijxQI1",
      "metadata": {
        "id": "k6Rr62ijxQI1"
      },
      "outputs": [],
      "source": [
        "def val_epoch(model, val_loader):\n",
        "  batch_losses = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for images, labels in tqdm(val_loader, desc=\"Validation: \"):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Forward pass\n",
        "      logits = model(images)\n",
        "      loss_value = ce_loss(logits, labels)\n",
        "      batch_losses.append(loss_value.item())\n",
        "  val_loss = np.mean(batch_losses)\n",
        "  return val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mp5M0FckyFFM",
      "metadata": {
        "id": "mp5M0FckyFFM"
      },
      "source": [
        "## 4.2 Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "TE16sUHmyFFS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TE16sUHmyFFS",
        "outputId": "f4389600-1cd4-4a23-d032-56aed46e1eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All random seeds set to 51 for reproducibility\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:14<00:00, 60.14it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 78.19it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train Loss: 0.3850 - Val Loss: 0.1241\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:12<00:00, 69.04it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 82.44it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Train Loss: 0.1720 - Val Loss: 0.1022\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:13<00:00, 67.09it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 82.75it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Train Loss: 0.1332 - Val Loss: 0.1088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:13<00:00, 66.87it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 91.33it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Train Loss: 0.1162 - Val Loss: 0.0967\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:13<00:00, 65.83it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 70.91it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Train Loss: 0.1052 - Val Loss: 0.1050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:12<00:00, 69.66it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 91.14it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Train Loss: 0.0982 - Val Loss: 0.1017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:12<00:00, 68.14it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 92.00it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Train Loss: 0.0919 - Val Loss: 0.0920\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:12<00:00, 67.54it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 84.05it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Train Loss: 0.0802 - Val Loss: 0.1119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:13<00:00, 66.99it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 89.31it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Train Loss: 0.0789 - Val Loss: 0.0892\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 874/874 [00:12<00:00, 67.46it/s]\n",
            "Validation: 100%|██████████| 141/141 [00:01<00:00, 84.92it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Train Loss: 0.0774 - Val Loss: 0.0915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Ensure reproducibility for the training process\n",
        "set_seeds(51) # You can change this number to get different results\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_model = None\n",
        "\n",
        "# Define the path to save the model within your hard-drive\n",
        "path = Path(os.getcwd()) # Feel free to change the path\n",
        "\n",
        "model_save_path = path / 'best_new_lenet.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, new_train_loader)\n",
        "    val_loss = val_epoch(model, new_val_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "        # Save the best model\n",
        "        torch.save(best_model.state_dict(), model_save_path)\n",
        "        print('Found and saved better weights for the model')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896ReOb8yFFT",
      "metadata": {
        "id": "896ReOb8yFFT"
      },
      "source": [
        "### visualize training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "K56o1pxCyFFV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "K56o1pxCyFFV",
        "outputId": "881f9d83-730e-49f6-e544-a37beeaec6fe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Find the epoch with the best validation loss\n",
        "best_epoch = np.argmin(val_losses) + 1 # Add 1 because epochs are 1-indexed\n",
        "\n",
        "# Add a vertical red line at the epoch with the best validation loss\n",
        "plt.axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Val Loss Epoch {best_epoch}')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KFRpHEfUyFFV",
      "metadata": {
        "id": "KFRpHEfUyFFV"
      },
      "source": [
        "### Load best version of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "scwOGFD4yFFV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scwOGFD4yFFV",
        "outputId": "fc620e7f-36e6-46d4-aa10-5ce6dcfebf8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully from /home/linus/HPI/cv-seminar/best_new_lenet.pth\n",
            "Model is on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Define the path where the best model was saved\n",
        "path = Path(os.getcwd())\n",
        "model_save_path = path / 'best_new_lenet.pth'\n",
        "\n",
        "# Instantiate a new model with the same architecture\n",
        "# Make sure you use the same model class that was trained\n",
        "loaded_model = NewModernLeNet5()\n",
        "\n",
        "# Load the saved state dictionary into the new model instance\n",
        "# Make sure the model is on the correct device (CPU or GPU)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
        "\n",
        "# Move the model to the device\n",
        "loaded_model = loaded_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully from {model_save_path}\")\n",
        "print(f\"Model is on device: {next(loaded_model.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D0aNi-_nZ7AQ",
      "metadata": {
        "id": "D0aNi-_nZ7AQ"
      },
      "source": [
        "## 4.3 Apply Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "0Jc7j_6jjZHP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jc7j_6jjZHP",
        "outputId": "5257760d-272c-4ebd-c249-b64e67e387d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying LeNet model to the train_dataset (using non-shuffled loader)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing train batches for inference: 100%|██████████| 797/797 [00:06<00:00, 127.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference on train_dataset complete.\n",
            "Shape of collected train logits: (51000, 11)\n",
            "Number of collected train predictions: 51000\n",
            "Storing predictions and logits as FiftyOne Classifications for train_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing train classifications: 100%|██████████| 51000/51000 [04:10<00:00, 203.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions and logits stored successfully as FiftyOne Classifications for train_dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# This uses the torch_train_set which is derived from train_dataset\n",
        "new_train_inference_loader = torch.utils.data.DataLoader(\n",
        "    new_torch_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # CRITICAL: Must be False for ordered predictions\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Set the loaded model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# Lists to store predictions and logits for the training set\n",
        "train_predictions = []\n",
        "train_all_logits = []\n",
        "\n",
        "# Run inference on the training set using the NON-SHUFFLED loader\n",
        "print(\"Applying LeNet model to the train_dataset (using non-shuffled loader)...\")\n",
        "with torch.inference_mode(): # Disable gradient calculation\n",
        "    # Use the new train_inference_loader\n",
        "    for images, _ in tqdm(new_train_inference_loader, desc=\"Processing train batches for inference\"):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        logits = loaded_model(images)\n",
        "        train_all_logits.append(logits.cpu().numpy()) # Store logits\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        train_predictions.extend(predicted.cpu().numpy()) # Store predictions\n",
        "\n",
        "# Concatenate logits from all batches\n",
        "train_all_logits = np.concatenate(train_all_logits, axis=0)\n",
        "\n",
        "print(\"Inference on train_dataset complete.\")\n",
        "print(f\"Shape of collected train logits: {train_all_logits.shape}\")\n",
        "print(f\"Number of collected train predictions: {len(train_predictions)}\")\n",
        "\n",
        "# Store the predictions and logits back into the FiftyOne dataset as Classification objects\n",
        "print(\"Storing predictions and logits as FiftyOne Classifications for train_dataset...\")\n",
        "for i, sample in enumerate(tqdm(new_train_dataset, desc=\"Storing train classifications\")):\n",
        "    predicted_idx = train_predictions[i]\n",
        "    predicted_label = new_classes[predicted_idx] # Assuming dataset_classes is consistent\n",
        "    sample_logits = train_all_logits[i]\n",
        "    confidences = Fun.softmax(torch.tensor(sample_logits), dim=0).numpy()\n",
        "    predicted_confidence = float(confidences[predicted_idx])\n",
        "    classification = fo.Classification(\n",
        "        label=predicted_label,\n",
        "        confidence=predicted_confidence,\n",
        "        logits=sample_logits.tolist()\n",
        "    )\n",
        "    sample[\"lenet_classification\"] = classification\n",
        "    sample.save()\n",
        "\n",
        "print(\"Predictions and logits stored successfully as FiftyOne Classifications for train_dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "8dbedd6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying LeNet model to the train_dataset (using non-shuffled loader)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing val batches for inference: 100%|██████████| 141/141 [00:03<00:00, 44.03it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference on train_dataset complete.\n",
            "Shape of collected val logits: (9000, 11)\n",
            "Number of collected val predictions: 9000\n",
            "Storing predictions and logits as FiftyOne Classifications for val_dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Storing val classifications: 100%|██████████| 9000/9000 [00:39<00:00, 230.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions and logits stored successfully as FiftyOne Classifications for val_dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# do the same for the validation dataset\n",
        "# This uses the torch_val_set which is derived from val_dataset\n",
        "new_val_inference_loader = torch.utils.data.DataLoader(\n",
        "    new_torch_val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # CRITICAL: Must be False for ordered predictions\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Set the loaded model to evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# Lists to store predictions and logits for the training set\n",
        "val_predictions = []\n",
        "val_all_logits = []\n",
        "\n",
        "# Run inference on the training set using the NON-SHUFFLED loader\n",
        "print(\"Applying LeNet model to the train_dataset (using non-shuffled loader)...\")\n",
        "with torch.inference_mode(): # Disable gradient calculation\n",
        "    # Use the new val_inference_loader\n",
        "    for images, _ in tqdm(new_val_inference_loader, desc=\"Processing val batches for inference\"):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        logits = loaded_model(images)\n",
        "        val_all_logits.append(logits.cpu().numpy()) # Store logits\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        val_predictions.extend(predicted.cpu().numpy()) # Store predictions\n",
        "# Concatenate logits from all batches\n",
        "val_all_logits = np.concatenate(val_all_logits, axis=0)\n",
        "\n",
        "print(\"Inference on train_dataset complete.\")\n",
        "print(f\"Shape of collected val logits: {val_all_logits.shape}\")\n",
        "print(f\"Number of collected val predictions: {len(val_predictions)}\")\n",
        "\n",
        "# Store the predictions and logits back into the FiftyOne dataset as Classification objects\n",
        "print(\"Storing predictions and logits as FiftyOne Classifications for val_dataset...\")\n",
        "for i, sample in enumerate(tqdm(new_val_dataset, desc=\"Storing val classifications\")):\n",
        "    predicted_idx = val_predictions[i]\n",
        "    predicted_label = new_classes[predicted_idx] # Assuming dataset_classes is consistent\n",
        "    sample_logits = val_all_logits[i]\n",
        "    confidences = Fun.softmax(torch.tensor(sample_logits), dim=0).numpy()\n",
        "    predicted_confidence = float(confidences[predicted_idx])\n",
        "    classification = fo.Classification(\n",
        "        label=predicted_label,\n",
        "        confidence=predicted_confidence,\n",
        "        logits=sample_logits.tolist()\n",
        "    )\n",
        "    sample[\"lenet_classification\"] = classification\n",
        "    sample.save()\n",
        "\n",
        "print(\"Predictions and logits stored successfully as FiftyOne Classifications for val_dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "5774f408",
      "metadata": {},
      "outputs": [],
      "source": [
        "new_lenet_train_evaluation_results = new_train_dataset.evaluate_classifications(\n",
        "    \"lenet_classification\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"lenet_eval\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "uQgmHcgGZ7AT",
      "metadata": {
        "id": "uQgmHcgGZ7AT"
      },
      "outputs": [],
      "source": [
        "new_lenet_val_evaluation_results = new_val_dataset.evaluate_classifications(\n",
        "    \"lenet_classification\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"lenet_eval\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9530b2ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "new_val_dataset.name = \"new-mnist-val\"\n",
        "new_train_dataset.name = \"new-mnist-train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "b99acaa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# add train_val and test datasets together and exclude difficult samples\n",
        "cleaned_dataset = train_val_dataset.clone()\n",
        "cleaned_dataset.merge_samples(test_dataset)\n",
        "cleaned_dataset = cleaned_dataset.exclude(cleaned_dataset.match(\n",
        "    fo.ViewField(\"filepath\").is_in(combined_difficult_samples))).clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "7eb7b640",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "69807"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cleaned_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "30428b46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pushing dataset to Hugging Face Hub: mnist-cleaned-full\n",
            "Dataset has more than 10,000 samples. Chunking by default to avoid exceeding the maximum number of files in a directory on Hugging Face Hub. Setting chunk_size to 1000.\n",
            "Directory '/tmp/tmpmlbaxwxv' already exists; export will be merged with existing files\n",
            "Exporting samples...\n",
            " 100% |████████████████| 69807/69807 [13.5s elapsed, 0s remaining, 6.2K docs/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   0%|          | 0/70 [00:00<?, ?it/s]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   1%|▏         | 1/70 [00:03<04:04,  3.54s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   3%|▎         | 2/70 [00:08<04:39,  4.11s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   4%|▍         | 3/70 [00:12<04:56,  4.43s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   6%|▌         | 4/70 [00:16<04:41,  4.27s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   7%|▋         | 5/70 [00:21<04:35,  4.23s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:   9%|▊         | 6/70 [00:25<04:44,  4.45s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  10%|█         | 7/70 [00:29<04:22,  4.17s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  11%|█▏        | 8/70 [00:33<04:20,  4.20s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  13%|█▎        | 9/70 [00:37<04:10,  4.10s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  14%|█▍        | 10/70 [00:42<04:15,  4.26s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  16%|█▌        | 11/70 [00:47<04:23,  4.47s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  17%|█▋        | 12/70 [00:51<04:16,  4.42s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  19%|█▊        | 13/70 [00:55<04:05,  4.30s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  20%|██        | 14/70 [00:59<03:55,  4.20s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  21%|██▏       | 15/70 [01:04<04:02,  4.42s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  23%|██▎       | 16/70 [01:08<04:00,  4.45s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  24%|██▍       | 17/70 [01:13<03:52,  4.39s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  26%|██▌       | 18/70 [01:18<04:00,  4.63s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  27%|██▋       | 19/70 [01:21<03:37,  4.26s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  29%|██▊       | 20/70 [01:25<03:25,  4.12s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  30%|███       | 21/70 [01:29<03:16,  4.00s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  31%|███▏      | 22/70 [01:33<03:10,  3.97s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  33%|███▎      | 23/70 [01:37<03:14,  4.14s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  34%|███▍      | 24/70 [01:41<03:06,  4.06s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  36%|███▌      | 25/70 [01:46<03:10,  4.23s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  37%|███▋      | 26/70 [01:50<03:01,  4.11s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  39%|███▊      | 27/70 [01:55<03:08,  4.39s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  40%|████      | 28/70 [01:59<03:09,  4.50s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  41%|████▏     | 29/70 [02:03<02:55,  4.29s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  43%|████▎     | 30/70 [02:08<02:53,  4.34s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  44%|████▍     | 31/70 [02:12<02:47,  4.30s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  46%|████▌     | 32/70 [02:16<02:36,  4.13s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  47%|████▋     | 33/70 [02:20<02:40,  4.34s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  49%|████▊     | 34/70 [02:25<02:36,  4.35s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  50%|█████     | 35/70 [02:30<02:36,  4.48s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  51%|█████▏    | 36/70 [02:33<02:26,  4.30s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  53%|█████▎    | 37/70 [02:38<02:21,  4.29s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  54%|█████▍    | 38/70 [02:42<02:15,  4.23s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  56%|█████▌    | 39/70 [02:46<02:13,  4.32s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  57%|█████▋    | 40/70 [02:50<02:06,  4.22s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  59%|█████▊    | 41/70 [02:54<02:01,  4.18s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  60%|██████    | 42/70 [02:58<01:53,  4.05s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  61%|██████▏   | 43/70 [03:03<01:54,  4.23s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  63%|██████▎   | 44/70 [03:07<01:52,  4.32s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  64%|██████▍   | 45/70 [03:11<01:44,  4.20s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  66%|██████▌   | 46/70 [03:15<01:35,  4.00s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  67%|██████▋   | 47/70 [03:20<01:37,  4.25s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  69%|██████▊   | 48/70 [03:23<01:30,  4.12s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  70%|███████   | 49/70 [03:27<01:25,  4.08s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  71%|███████▏  | 50/70 [03:32<01:21,  4.09s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  73%|███████▎  | 51/70 [03:36<01:19,  4.16s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  74%|███████▍  | 52/70 [03:40<01:15,  4.21s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  76%|███████▌  | 53/70 [03:44<01:11,  4.18s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  77%|███████▋  | 54/70 [03:49<01:08,  4.28s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  79%|███████▊  | 55/70 [03:54<01:09,  4.65s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  80%|████████  | 56/70 [03:59<01:05,  4.64s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  81%|████████▏ | 57/70 [04:03<00:59,  4.55s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  83%|████████▎ | 58/70 [04:07<00:52,  4.34s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  84%|████████▍ | 59/70 [04:12<00:49,  4.53s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "Uploading media files in 70 batches of size 1000:  86%|████████▌ | 60/70 [04:16<00:44,  4.42s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  87%|████████▋ | 61/70 [04:29<01:01,  6.83s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  89%|████████▊ | 62/70 [04:42<01:11,  8.90s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  90%|█████████ | 63/70 [04:56<01:12, 10.35s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  91%|█████████▏| 64/70 [05:10<01:08, 11.42s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  93%|█████████▎| 65/70 [05:24<01:00, 12.18s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  94%|█████████▍| 66/70 [05:37<00:49, 12.33s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  96%|█████████▌| 67/70 [05:50<00:37, 12.56s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  97%|█████████▋| 68/70 [06:03<00:25, 12.88s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000:  99%|█████████▊| 69/70 [06:18<00:13, 13.50s/it]It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
            "Uploading media files in 70 batches of size 1000: 100%|██████████| 70/70 [06:29<00:00,  5.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'mnist-cleaned-full' successfully pushed to Hugging Face Hub!\n"
          ]
        }
      ],
      "source": [
        "# publish to Hugging Face Hub\n",
        "hf_dataset_name = \"mnist-cleaned-full\"\n",
        "print(f\"\\nPushing dataset to Hugging Face Hub: {hf_dataset_name}\")\n",
        "fouh.push_to_hub(cleaned_dataset, hf_dataset_name, exist_ok=True)\n",
        "print(f\"Dataset '{hf_dataset_name}' successfully pushed to Hugging Face Hub!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b22b4ff8",
      "metadata": {},
      "source": [
        "find the dataset [here](https://huggingface.co/datasets/Linus-L/mnist-cleaned-full)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wJGsyXc_HAZ5",
        "8C29CIg_a0Si",
        "AY5sqIYwUrIs",
        "eVEsqzKpZbui",
        "6ef650e7",
        "JFRP06l7eJv_",
        "9bzic-_4eHkp",
        "XXdPU-XkxQIs"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1355d0e7ccca4c64b769b00aff29d84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d38390d2d634415ab0abdea74b4523d4",
            "placeholder": "​",
            "style": "IPY_MODEL_b31d9dfe084844f09d6727ceccbcb519",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "1ee7b2d5802f4a5bb25439e6619f8b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200f12c50f09419781eb83b624d88d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "201bcac0fce44f96945bc86243c3b51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_818a672533e143d88e53754cf21508fb",
            "style": "IPY_MODEL_5b0f527eec5b4b5e91468413849f9fd0",
            "value": true
          }
        },
        "32a3cd6e01f44498a2eab8004cd1fc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee7b2d5802f4a5bb25439e6619f8b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_8ba3c9ed82974d55945db76b8a65d5f4",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "32ac3c35b6f04082961e28bc9c7bde6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466698f9b1104e81ada86cd60650d9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_68153618c121498f94bb16ee795c85d6",
            "style": "IPY_MODEL_d5a83cfd591941d697c1c35c029359c9",
            "tooltip": ""
          }
        },
        "538b843eb3d04f3a92158a7e56873500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32a3cd6e01f44498a2eab8004cd1fc68",
              "IPY_MODEL_f7dbc1749aca4b81bb145c9612f399f2",
              "IPY_MODEL_201bcac0fce44f96945bc86243c3b51c",
              "IPY_MODEL_466698f9b1104e81ada86cd60650d9d6",
              "IPY_MODEL_1355d0e7ccca4c64b769b00aff29d84d"
            ],
            "layout": "IPY_MODEL_6524ac0a3aae46488b4ef9e2c4767d6b"
          }
        },
        "5b0f527eec5b4b5e91468413849f9fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6524ac0a3aae46488b4ef9e2c4767d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "68153618c121498f94bb16ee795c85d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818a672533e143d88e53754cf21508fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba3c9ed82974d55945db76b8a65d5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b31d9dfe084844f09d6727ceccbcb519": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d38390d2d634415ab0abdea74b4523d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a83cfd591941d697c1c35c029359c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f7dbc1749aca4b81bb145c9612f399f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_32ac3c35b6f04082961e28bc9c7bde6e",
            "placeholder": "​",
            "style": "IPY_MODEL_200f12c50f09419781eb83b624d88d68",
            "value": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
